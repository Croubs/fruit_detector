{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 16:52:11.500697: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 16:52:12.001926: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 16:52:12.348289: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731970332.603520   10437 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731970332.672988   10437 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 16:52:13.609906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del directorio y parámetros de las imágenes\n",
    "data_dir = './dataset'  # Ruta al dataset que tienes en tu PC\n",
    "image_size = (224, 224)  # Tamaño de las imágenes que utilizará el modelo\n",
    "batch_size = 32  # Tamaño del lote para entrenamiento\n",
    "num_classes = 12  # Número de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11759 images belonging to 12 classes.\n",
      "Found 2934 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generador de datos con separación de entrenamiento y validación\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Normalización y división\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Multi-clase para reconocer tipo de fruta y frescura\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Conjunto de validación\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fresh_apple', 'fresh_banana', 'fresh_bitter_gourd', 'fresh_capsicum', 'fresh_orange', 'fresh_tomato', 'stale_apple', 'stale_banana', 'stale_bitter_gourd', 'stale_capsicum', 'stale_orange', 'stale_tomato']\n"
     ]
    }
   ],
   "source": [
    "# Crear lista de nombres de clases basados en el orden de los índices\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/croubs/Escritorio/Repos/PIA-IA-2.5/env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-18 16:52:17.391546: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-11-18 16:52:17.454065: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "2024-11-18 16:52:17.480393: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "2024-11-18 16:52:17.572638: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Definición del modelo de red neuronal convolucional (CNN)\n",
    "model = Sequential([\n",
    "    # Primera capa convolucional con regularización L2\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Segunda capa convolucional con regularización L2\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Tercera capa convolucional con regularización L2\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Aplanamiento para conectar con las capas densas\n",
    "    Flatten(),\n",
    "    \n",
    "    # Primera capa densa con regularización L2 y Dropout\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),  # Aplica Dropout para reducir overfitting\n",
    "    \n",
    "    # Capa de salida para clasificar (softmax para multi-clase)\n",
    "    Dense(num_classes, activation='softmax')  # 'num_classes' es el número total de categorías\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/croubs/Escritorio/Repos/PIA-IA-2.5/env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 16:52:19.220551: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n",
      "2024-11-18 16:52:19.861476: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 44302336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 2s/step - accuracy: 0.4365 - loss: 2.7525 - val_accuracy: 0.6738 - val_loss: 1.3337 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 2s/step - accuracy: 0.7270 - loss: 1.2789 - val_accuracy: 0.7369 - val_loss: 1.1088 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 2s/step - accuracy: 0.7465 - loss: 1.1324 - val_accuracy: 0.7621 - val_loss: 0.9883 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 2s/step - accuracy: 0.7759 - loss: 1.0277 - val_accuracy: 0.8003 - val_loss: 0.8831 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 2s/step - accuracy: 0.7843 - loss: 0.9806 - val_accuracy: 0.8183 - val_loss: 0.8986 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 2s/step - accuracy: 0.8022 - loss: 0.9437 - val_accuracy: 0.7829 - val_loss: 0.8776 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 2s/step - accuracy: 0.7948 - loss: 0.9448 - val_accuracy: 0.8010 - val_loss: 0.8968 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 2s/step - accuracy: 0.8165 - loss: 0.9083 - val_accuracy: 0.7996 - val_loss: 0.8725 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 2s/step - accuracy: 0.8177 - loss: 0.8781 - val_accuracy: 0.7110 - val_loss: 1.0504 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 2s/step - accuracy: 0.8109 - loss: 0.8836 - val_accuracy: 0.7570 - val_loss: 0.9580 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 2s/step - accuracy: 0.8252 - loss: 0.8401 - val_accuracy: 0.7873 - val_loss: 0.8747 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m719s\u001b[0m 2s/step - accuracy: 0.8439 - loss: 0.7678 - val_accuracy: 0.8323 - val_loss: 0.7056 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.8630 - loss: 0.6687 - val_accuracy: 0.8674 - val_loss: 0.6507 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 2s/step - accuracy: 0.8668 - loss: 0.6448 - val_accuracy: 0.8746 - val_loss: 0.6509 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m709s\u001b[0m 2s/step - accuracy: 0.8719 - loss: 0.6389 - val_accuracy: 0.8286 - val_loss: 0.7279 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.8732 - loss: 0.6376 - val_accuracy: 0.8149 - val_loss: 0.7063 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 2s/step - accuracy: 0.8889 - loss: 0.5762 - val_accuracy: 0.8504 - val_loss: 0.5982 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m712s\u001b[0m 2s/step - accuracy: 0.8972 - loss: 0.5239 - val_accuracy: 0.8783 - val_loss: 0.6195 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m709s\u001b[0m 2s/step - accuracy: 0.9004 - loss: 0.5192 - val_accuracy: 0.8851 - val_loss: 0.5901 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m711s\u001b[0m 2s/step - accuracy: 0.8973 - loss: 0.5133 - val_accuracy: 0.8698 - val_loss: 0.6026 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.9034 - loss: 0.5168 - val_accuracy: 0.8514 - val_loss: 0.6484 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.9019 - loss: 0.4985 - val_accuracy: 0.8695 - val_loss: 0.5584 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 2s/step - accuracy: 0.9017 - loss: 0.5002 - val_accuracy: 0.8804 - val_loss: 0.5582 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 2s/step - accuracy: 0.9065 - loss: 0.4882 - val_accuracy: 0.9022 - val_loss: 0.5253 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.9069 - loss: 0.4873 - val_accuracy: 0.8671 - val_loss: 0.5458 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 2s/step - accuracy: 0.9070 - loss: 0.4964 - val_accuracy: 0.8572 - val_loss: 0.5678 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m708s\u001b[0m 2s/step - accuracy: 0.9011 - loss: 0.5020 - val_accuracy: 0.8845 - val_loss: 0.5948 - learning_rate: 2.5000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 2s/step - accuracy: 0.9251 - loss: 0.4489 - val_accuracy: 0.8882 - val_loss: 0.5430 - learning_rate: 1.2500e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 2s/step - accuracy: 0.9283 - loss: 0.4220 - val_accuracy: 0.9052 - val_loss: 0.4832 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 2s/step - accuracy: 0.9270 - loss: 0.4230 - val_accuracy: 0.9049 - val_loss: 0.4803 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del modelo con más epochs\n",
    "epochs = 30  # Aumentado\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[lr_reduction, early_stop]  # Agrega los callbacks aquí\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 469ms/step - accuracy: 0.9032 - loss: 0.4760\n",
      "Loss en validación: 0.4803222715854645\n",
      "Precisión en validación: 0.9049080014228821\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo en el conjunto de validación\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Loss en validación: {val_loss}\")\n",
    "print(f\"Precisión en validación: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save(\"modelo_clasificacion_frutas.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
